from fastapi import FastAPI
from pydantic import BaseModel
import uvicorn
import torch
import torch.nn.functional as F
from transformers import AutoTokenizer, AutoModelForSequenceClassification

# ==========================================
# 1. AI ëª¨ë¸ ë¡œë“œ
# ==========================================
print("â³ AI ëª¨ë¸ì„ ë¡œë”© ì¤‘ì…ë‹ˆë‹¤...")
model_path = "./emotion_model"  # í´ë” ì´ë¦„ ê¼­ í™•ì¸í•˜ì„¸ìš”!

try:
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    model = AutoModelForSequenceClassification.from_pretrained(model_path)
    model.eval()
    print("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
except Exception as e:
    print(f"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨! {e}")
    # ì‹¤íŒ¨í•˜ë©´ ë”ë¯¸ ëª¨ë¸ë¡œë¼ë„ ì‘ë™í•˜ê²Œ ì˜ˆì™¸ì²˜ë¦¬ (ê¸‰í•˜ë‹ˆê¹Œ)
    model = None

# íŒ€ì› ëª¨ë¸ì˜ 6ê°œ ë¼ë²¨ (ìˆœì„œ ì¤‘ìš”! íŒ€ì› ì½”ë“œ ê¸°ì¤€ 0~5)
ID2LABEL = {
    0: "ê¸°ì¨",
    1: "ë‹¹í™©",
    2: "ë¶„ë…¸",
    3: "ë¶ˆì•ˆ",
    4: "ìƒì²˜",  # <-- ì•±ì—ëŠ” ì—†ëŠ” ê°ì •
    5: "ìŠ¬í””"
}

# ì•±(Flutter)ì—ì„œ ì‚¬ìš©í•˜ëŠ” ì˜ì–´ í‚¤ ë§¤í•‘ (ìƒì²˜ëŠ” ì œì™¸ë¨)
KOREAN_TO_ENGLISH = {
    "ê¸°ì¨": "joy",
    "ë‹¹í™©": "surprise",
    "ë¶„ë…¸": "anger",
    "ë¶ˆì•ˆ": "fear",
    "ìŠ¬í””": "sadness"
    # "ìƒì²˜"ëŠ” ì—¬ê¸°ì— ì—†ìŒ -> ë¡œì§ì—ì„œ ê±¸ëŸ¬ëƒ„
}

# ==========================================
# 2. FastAPI ì„¤ì •
# ==========================================
app = FastAPI()

class TextRequest(BaseModel):
    text: str

# ì„ ë¬¼ ë§í¬ (ê¸°ì¡´ ìœ ì§€)
LINKS = {
    "joy": "https://gift.kakao.com/product/10618518",
    "surprise": "https://gift.kakao.com/product/11561204",
    "anger": "https://gift.kakao.com/product/9314157",
    "fear": "https://gift.kakao.com/product/4764917",
    "sadness": "https://gift.kakao.com/product/11914005"
}

# ==========================================
# 3. í•µì‹¬ ë¡œì§: 2ìˆœìœ„ ê°ì • ì°¾ê¸°
# ==========================================
def predict_emotion(sentence):
    if model is None: return "ê¸°ì¨" # ëª¨ë¸ ì—†ìœ¼ë©´ ê·¸ëƒ¥ ê¸°ì¨ ë¦¬í„´

    # 1. ì¶”ë¡  (Inference)
    inputs = tokenizer(sentence, return_tensors="pt", truncation=True)
    with torch.no_grad():
        outputs = model(**inputs)
        logits = outputs.logits
        # Softmaxë¡œ í™•ë¥ (%) ê³„ì‚°
        probs = F.softmax(logits, dim=1)[0]

    # 2. í™•ë¥  ë†’ì€ ìˆœì„œëŒ€ë¡œ ì •ë ¬ [(í™•ë¥ , ë¼ë²¨ì¸ë±ìŠ¤), ...]
    # ì˜ˆ: [(0.8, 4='ìƒì²˜'), (0.15, 5='ìŠ¬í””'), ...]
    probs_list = []
    for i, prob in enumerate(probs):
        probs_list.append((prob.item(), i))
    
    # í™•ë¥  ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬ (ë‚´ë¦¼ì°¨ìˆœ)
    probs_list.sort(key=lambda x: x[0], reverse=True)

    # 3. ì•±ì—ì„œ ì“¸ ìˆ˜ ìˆëŠ” ê°ì •ì¸ì§€ í™•ì¸ (ìˆœì„œëŒ€ë¡œ ì²´í¬)
    final_emotion_kor = "ìŠ¬í””" # ê¸°ë³¸ê°’
    
    for prob, idx in probs_list:
        korean_label = ID2LABEL[idx]
        
        # ë§Œì•½ ì´ ë¼ë²¨ì´ ë‚´ ì•±(ì˜ì–´í‚¤ ë§¤í•‘)ì— ìˆë‹¤ë©´? -> ì±„íƒ!
        if korean_label in KOREAN_TO_ENGLISH:
            final_emotion_kor = korean_label
            print(f"ğŸ‘‰ ì„ íƒëœ ê°ì •: {korean_label} (í™•ë¥ : {prob*100:.1f}%)")
            break
        else:
            # ìƒì²˜ ì²˜ëŸ¼ ì•±ì— ì—†ëŠ” ë¼ë²¨ì´ë©´? -> íŒ¨ìŠ¤í•˜ê³  ë‹¤ìŒìœ¼ë¡œ ë†’ì€ ê±° ë´„
            print(f"ğŸš« ìŠ¤í‚µëœ ê°ì •: {korean_label} (ì•± ë¯¸ì§€ì›)")

    return final_emotion_kor

# ==========================================
# 4. API ì—”ë“œí¬ì¸íŠ¸
# ==========================================
@app.post("/analyze")
async def analyze(request: TextRequest):
    input_text = request.text.strip()
    
    # AI ì˜ˆì¸¡ ìˆ˜í–‰
    korean_emotion = predict_emotion(input_text)
    
    # ì˜ì–´ë¡œ ë³€í™˜ (ìœ„ì—ì„œ í•„í„°ë§í–ˆìœ¼ë¯€ë¡œ ë¬´ì¡°ê±´ ìˆìŒ)
    english_emotion = KOREAN_TO_ENGLISH[korean_emotion]
    link = LINKS[english_emotion]

    return {
        "text": input_text,
        "emotion": english_emotion,
        "original_emotion": korean_emotion,
        "link": link
    }

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)